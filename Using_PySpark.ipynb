{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using PySpark.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPE6BTIX4ehP3wcDksV/HIu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apremjee/Data_Formats/blob/master/Using_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCvA1P0hjbae"
      },
      "source": [
        "## Objective\n",
        "The objective of this notebook is to:\n",
        "\n",
        "Give a proper understanding about the different PySpark functions available.\n",
        "A short introduction to Google Colab, as that is the platform on which this notebook is written on.\n",
        "Once you complete this notebook, you should be able to write pyspark programs in an efficent way. The ideal way to use this is by going through the examples given and then trying them on Colab. At the end there are a few hands on questions which you can use to evaluate yourself.\n",
        "\n",
        "\n",
        "#### Prerequisite\n",
        "Although some theory about pyspark and big data will be given in this notebook, I recommend everyone to read more about it and have a deeper understanding on how the functions get executed and the relevance of big data in the current scenario.\n",
        "A good understanding on python will be an added bonus.\n",
        "\n",
        "Notes from the Author\n",
        "This tutorial was made using Google Colab so the code you see here is meant to run on a colab notebook.\n",
        "It goes through basic PySpark Functions and a short introduction on how to use Colab.\n",
        "If you want to view my colab notebook for this particular tutorial, you can view it here. The viewing experience and readability is much better there.\n",
        "If you want to try out things with this notebook as a base, feel free to download it from my repo here and then use it with jupyter notebook.\n",
        "\n",
        "\n",
        "### Big data, PySpark and Colaboratory\n",
        "\n",
        "#### Big data\n",
        "Big data usually means data of such huge volume that normal data storage solutions cannot efficently store and process it. In this era, data is being generated at an absurd rate. Data is collected for each movement a person makes. The bulk of big data comes from three primary sources:\n",
        "\n",
        "- Social data\n",
        "- Machine data\n",
        "- Transactional data\n",
        "Some common examples for the sources of such data include internet searches, facebook posts, doorbell cams, smartwatches, online shopping history etc. Every action creates data, it is just a matter of of there is a way to collect them or not. But what's interesting is that out of all this data collected, not even 5% of it is being used fully. There is a huge demand for big data professionals in the industry. Even though the number of graduates with a specialization in big data are rising, the problem is that they don't have the practical knowledge about big data scenarios, which leads to bad architecutres and inefficent methods of processing data.\n",
        "\n",
        "If you are interested to know more about the landscape and technologies involved, here is an article which I found really interesting!\n",
        "\n",
        "\n",
        "###PySpark\n",
        "If you are working in the field of big data, you must have definelty heard of spark. If you look at the Apache Spark website, you will see that it is said to be a Lightning-fast unified analytics engine. PySpark is a flavour of Spark used for processing and analysing massive volumes of data. If you are familiar with python and have tried it for huge datasets, you should know that the execution time can get ridiculous. Enter PySpark!\n",
        "\n",
        "Imagine your data resides in a distributed manner at different places. If you try brining your data to one point and executing your code there, not only would that be inefficent, but also cause memory issues. Now let's say your code goes to the data rather than the data coming to where your code. This will help avoid unneccesary data movement which will thereby decrease the running time.\n",
        "\n",
        "PySpark is the Python API of Spark; which means it can do almost all the things python can. Machine learning(ML) pipelines, exploratory data analysis (at scale), ETLs for data platform, and much more! And all of them in a distributed manner. One of the best parts of pyspark is that if you are already familiar with python, it's really easy to learn.\n",
        "\n",
        "Apart from PySpark, there is another language called Scala used for big data processing. Scala is frequently over 10 times faster than Python, as it is native for Hadoop as its based on JVM. But PySpark is getting adopted at a fast rate because of the ease of use, easier learning curve and ML capabilities.\n",
        "\n",
        "I will briefly explain how a PySpark job works, but I strongly recommend you read more about the architecture and how everything works. Now, before I get into it, let me talk about some basic jargons first:\n",
        "\n",
        "- Cluster is a set of loosely or tightly connected computers that work together so that they can be viewed as a single system.\n",
        "\n",
        "- Hadoop is an open source, scalable, and fault tolerant framework written in Java. It efficiently processes large volumes of data on a cluster of commodity hardware. Hadoop is not only a storage system but is a platform for large data storage as well as processing.\n",
        "\n",
        "- HDFS (Hadoop distributed file system). It is one of the world's most reliable storage system. HDFS is a Filesystem of Hadoop designed for storing very large files running on a cluster of commodity hardware.\n",
        "\n",
        "- MapReduce is a data Processing framework, which has 2 phases - Mapper and Reducer. The map procedure performs filtering and sorting, and the reduce method performs a summary operation. It usually runs on a hadoop cluster.\n",
        "\n",
        "- Transformation refers to the operations applied on a dataset to create a new dataset. Filter, groupBy and map are the examples of transformations.\n",
        "\n",
        "- Actions Actions refer to an operation which instructs Spark to perform computation and send the result back to driver. This is an example of action.\n",
        "\n",
        "Alright! Now that that's out of the way, let me explain how a spark job runs. In simple terma, each time you submit a pyspark job, the code gets internally converted into a MapReduce program and gets executed in the Java virtual machine. Now one of the thoughts that might be popping in your mind will probably be:\n",
        "So the code gets converted into a MapReduce program. Wouldn't that mean MapReduce is faster than pySpark?\n",
        "Well, the answer is a big NO. This is what makes spark jobs special. Spark is capable of handling a massive amount of data at a time, in it's distributed environment. It does this through in-memory processing, which is what makes it almost 100 times faster than Hadoop. Another factor which amkes it fast is Lazy Evaluation. Spark delays its evaluation as much as it can. Each time you submit a job, spark creates an action plan for how to execute the code, and then does nothing. Finally, when you ask for the result(i.e, calls an action), it executes the plan, which is basically all the transofrmations you have mentioned in your code. That's basically the gist of it.\n",
        "\n",
        "Now lastly, I want to talk about on more thing. Spark mainly consists of 4 modules:\n",
        "\n",
        "- Spark SQL - helps to write spark programs using SQL like queries.\n",
        "- Spark Streaming - is an extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams. used heavily in processing of social media data.\n",
        "- Spark MLLib - is the machine learning component of SPark. It helps train ML models on massive datasets with very high efficeny.\n",
        "- Spark GraphX - is the visualization component of Spark. It enables users to view data both as graphs and as collections without data movement or duplication.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr-Uziz6krxQ",
        "outputId": "8755c413-31a7-4b3c-d83c-e89db925781f"
      },
      "source": [
        "ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34mspark-3.1.1-bin-hadoop3.2\u001b[0m/  spark-3.1.1-bin-hadoop3.2.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FsyPaX5RkuuT",
        "outputId": "ee7e2079-6768-4ab1-fcde-8d6a9970b422"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rlKMkOrhLpH",
        "outputId": "6c1cfafb-04e0-48f8-bb8c-41a1150bd390"
      },
      "source": [
        "# !pip install pyspark"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 65 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 65.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=958bf70344b061a15bb541b1f4db4208ce5c1aedc038a0be65b3ccdcfeefdd73\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psuxZNXyjCHt"
      },
      "source": [
        "### Installing Spark\n",
        "#### Install Dependencies:\n",
        "\n",
        "- Java 8\n",
        "- Apache Spark with hadoop and\n",
        "- Findspark (used to locate the spark in the system)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IFC3k2OiruM"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k7kVQ_fjTEZ"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGuSCxnclG1w"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "ZuxkfOFblL7E",
        "outputId": "93bb7f17-5f48-44fa-ccdc-c53b97f499e7"
      },
      "source": [
        "spark"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://73c2c86ab978:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f5569942990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5eZPYQoluR4"
      },
      "source": [
        "#### Load a dataset and explore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LauDOgPglfHe",
        "outputId": "a074a5a7-d5b3-42c4-d384-79d36ea4717a"
      },
      "source": [
        "# Downloading and preprocessing Cars Data downloaded origianlly from https://perso.telecom-paristech.fr/eagan/class/igr204/datasets\n",
        "# Many of these datasets have been cleaned up by Petra Isenberg, Pierre Dragicevic and Yvonne Jansen\n",
        "!wget https://jacobceles.github.io/knowledge_repo/colab_and_pyspark/cars.csv"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-08 16:26:55--  https://jacobceles.github.io/knowledge_repo/colab_and_pyspark/cars.csv\n",
            "Resolving jacobceles.github.io (jacobceles.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to jacobceles.github.io (jacobceles.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://jacobcelestine.com/knowledge_repo/colab_and_pyspark/cars.csv [following]\n",
            "--2021-08-08 16:26:55--  https://jacobcelestine.com/knowledge_repo/colab_and_pyspark/cars.csv\n",
            "Resolving jacobcelestine.com (jacobcelestine.com)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to jacobcelestine.com (jacobcelestine.com)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22608 (22K) [text/csv]\n",
            "Saving to: ‘cars.csv’\n",
            "\n",
            "cars.csv            100%[===================>]  22.08K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-08-08 16:26:55 (25.1 MB/s) - ‘cars.csv’ saved [22608/22608]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZZtOhWJl93A",
        "outputId": "e501b0af-ee50-4d21-f328-e4716fd92c50"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cars.csv  sample_data  spark-3.1.1-bin-hadoop3.2  spark-3.1.1-bin-hadoop3.2.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFRy8f6pmH4A",
        "outputId": "4f464824-ff21-4935-e0ce-367bf4c4774a"
      },
      "source": [
        "# Load data from csv to a dataframe. \n",
        "# header=True means the first row is a header \n",
        "# sep=';' means the column are seperated using ''\n",
        "df = spark.read.csv('cars.csv', header=True, sep=\";\")\n",
        "df.show(5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|\n",
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|Chevrolet Chevell...|18.0|        8|       307.0|     130.0| 3504.|        12.0|   70|    US|\n",
            "|   Buick Skylark 320|15.0|        8|       350.0|     165.0| 3693.|        11.5|   70|    US|\n",
            "|  Plymouth Satellite|18.0|        8|       318.0|     150.0| 3436.|        11.0|   70|    US|\n",
            "|       AMC Rebel SST|16.0|        8|       304.0|     150.0| 3433.|        12.0|   70|    US|\n",
            "|         Ford Torino|17.0|        8|       302.0|     140.0| 3449.|        10.5|   70|    US|\n",
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f0AvAc6mMyp",
        "outputId": "2662a633-7cbb-4e60-b697-e89559db6a77"
      },
      "source": [
        "df.head(5) # head here has a different context"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Car='Chevrolet Chevelle Malibu', MPG='18.0', Cylinders='8', Displacement='307.0', Horsepower='130.0', Weight='3504.', Acceleration='12.0', Model='70', Origin='US'),\n",
              " Row(Car='Buick Skylark 320', MPG='15.0', Cylinders='8', Displacement='350.0', Horsepower='165.0', Weight='3693.', Acceleration='11.5', Model='70', Origin='US'),\n",
              " Row(Car='Plymouth Satellite', MPG='18.0', Cylinders='8', Displacement='318.0', Horsepower='150.0', Weight='3436.', Acceleration='11.0', Model='70', Origin='US'),\n",
              " Row(Car='AMC Rebel SST', MPG='16.0', Cylinders='8', Displacement='304.0', Horsepower='150.0', Weight='3433.', Acceleration='12.0', Model='70', Origin='US'),\n",
              " Row(Car='Ford Torino', MPG='17.0', Cylinders='8', Displacement='302.0', Horsepower='140.0', Weight='3449.', Acceleration='10.5', Model='70', Origin='US')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ6S8k8oyjAL"
      },
      "source": [
        "The above command loads our data from into a dataframe (DF). A dataframe is a 2-dimensional labeled data structure with columns of potentially different types.\n",
        "\n",
        "\n",
        "### Viewing the Dataframe¶\n",
        "There are a couple of ways to view your dataframe(DF) in PySpark:\n",
        "\n",
        "- df.take(5) will return a list of five Row objects.\n",
        "- df.collect() will get all of the data from the entire DataFrame. Be really careful when using it, because if you have a large data set, you can easily crash the driver node.\n",
        "- df.show() is the most commonly used method to view a dataframe. There are a few parameters we can pass to this method, like the number of rows and truncation. For example, df.show(5, False) or df.show(5, truncate=False) will show the entire data wihtout any truncation.\n",
        "- df.limit(5) will return a new DataFrame by taking the first n rows. As spark is distributed in nature, there is no guarantee that df.limit() will give you the same results each time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vntmaQGvy8mJ",
        "outputId": "6770b3e3-f785-4777-a763-930753479c12"
      },
      "source": [
        "df.take(5) # similar to head(5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Car='Chevrolet Chevelle Malibu', MPG='18.0', Cylinders='8', Displacement='307.0', Horsepower='130.0', Weight='3504.', Acceleration='12.0', Model='70', Origin='US'),\n",
              " Row(Car='Buick Skylark 320', MPG='15.0', Cylinders='8', Displacement='350.0', Horsepower='165.0', Weight='3693.', Acceleration='11.5', Model='70', Origin='US'),\n",
              " Row(Car='Plymouth Satellite', MPG='18.0', Cylinders='8', Displacement='318.0', Horsepower='150.0', Weight='3436.', Acceleration='11.0', Model='70', Origin='US'),\n",
              " Row(Car='AMC Rebel SST', MPG='16.0', Cylinders='8', Displacement='304.0', Horsepower='150.0', Weight='3433.', Acceleration='12.0', Model='70', Origin='US'),\n",
              " Row(Car='Ford Torino', MPG='17.0', Cylinders='8', Displacement='302.0', Horsepower='140.0', Weight='3449.', Acceleration='10.5', Model='70', Origin='US')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQQJIoqyzO0R",
        "outputId": "cfb3907a-2b2a-4a97-8484-a4aa81e05c15"
      },
      "source": [
        "df.show(5, truncate=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504. |12.0        |70   |US    |\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693. |11.5        |70   |US    |\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436. |11.0        |70   |US    |\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433. |12.0        |70   |US    |\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449. |10.5        |70   |US    |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "PQn_m-2OzaDg",
        "outputId": "75c40085-cf15-4037-c1f3-fa4776b4a8ef"
      },
      "source": [
        "df.limit(5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>Car</th><th>MPG</th><th>Cylinders</th><th>Displacement</th><th>Horsepower</th><th>Weight</th><th>Acceleration</th><th>Model</th><th>Origin</th></tr>\n",
              "<tr><td>Chevrolet Chevell...</td><td>18.0</td><td>8</td><td>307.0</td><td>130.0</td><td>3504.</td><td>12.0</td><td>70</td><td>US</td></tr>\n",
              "<tr><td>Buick Skylark 320</td><td>15.0</td><td>8</td><td>350.0</td><td>165.0</td><td>3693.</td><td>11.5</td><td>70</td><td>US</td></tr>\n",
              "<tr><td>Plymouth Satellite</td><td>18.0</td><td>8</td><td>318.0</td><td>150.0</td><td>3436.</td><td>11.0</td><td>70</td><td>US</td></tr>\n",
              "<tr><td>AMC Rebel SST</td><td>16.0</td><td>8</td><td>304.0</td><td>150.0</td><td>3433.</td><td>12.0</td><td>70</td><td>US</td></tr>\n",
              "<tr><td>Ford Torino</td><td>17.0</td><td>8</td><td>302.0</td><td>140.0</td><td>3449.</td><td>10.5</td><td>70</td><td>US</td></tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
              "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|\n",
              "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
              "|Chevrolet Chevell...|18.0|        8|       307.0|     130.0| 3504.|        12.0|   70|    US|\n",
              "|   Buick Skylark 320|15.0|        8|       350.0|     165.0| 3693.|        11.5|   70|    US|\n",
              "|  Plymouth Satellite|18.0|        8|       318.0|     150.0| 3436.|        11.0|   70|    US|\n",
              "|       AMC Rebel SST|16.0|        8|       304.0|     150.0| 3433.|        12.0|   70|    US|\n",
              "|         Ford Torino|17.0|        8|       302.0|     140.0| 3449.|        10.5|   70|    US|\n",
              "+--------------------+----+---------+------------+----------+------+------------+-----+------+"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qMiM9Rezqo0"
      },
      "source": [
        "### Viewing Dataframe Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH3Qur4GzlN3",
        "outputId": "f0b5fa6b-1aff-4027-f3d7-6ad1225cef8a"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Car',\n",
              " 'MPG',\n",
              " 'Cylinders',\n",
              " 'Displacement',\n",
              " 'Horsepower',\n",
              " 'Weight',\n",
              " 'Acceleration',\n",
              " 'Model',\n",
              " 'Origin']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSMlyk0kz4hY"
      },
      "source": [
        "#### Dataframe Schema¶\n",
        "There are two methods commonly used to view the data types of a dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgmuLdwiz8oP",
        "outputId": "1c26d99e-dd18-4c32-fa11-135add6eb8d1"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Car', 'string'),\n",
              " ('MPG', 'string'),\n",
              " ('Cylinders', 'string'),\n",
              " ('Displacement', 'string'),\n",
              " ('Horsepower', 'string'),\n",
              " ('Weight', 'string'),\n",
              " ('Acceleration', 'string'),\n",
              " ('Model', 'string'),\n",
              " ('Origin', 'string')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG25tOtf0C5H",
        "outputId": "2bf8b267-6fa8-4d1e-e50c-068c100212e7"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Car: string (nullable = true)\n",
            " |-- MPG: string (nullable = true)\n",
            " |-- Cylinders: string (nullable = true)\n",
            " |-- Displacement: string (nullable = true)\n",
            " |-- Horsepower: string (nullable = true)\n",
            " |-- Weight: string (nullable = true)\n",
            " |-- Acceleration: string (nullable = true)\n",
            " |-- Model: string (nullable = true)\n",
            " |-- Origin: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb14HiLR0R0H"
      },
      "source": [
        "### Inferring Schema Implicitly\n",
        "We can use the parameter inferschema=true to infer the input schema automatically while loading the data. An example is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7hFywCx0Wqc",
        "outputId": "5a514936-21c8-415f-a943-e2ce919d1b8e"
      },
      "source": [
        "df = spark.read.csv('cars.csv', header=True, sep=\";\", inferSchema=True)\n",
        "df.printSchema()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Car: string (nullable = true)\n",
            " |-- MPG: double (nullable = true)\n",
            " |-- Cylinders: integer (nullable = true)\n",
            " |-- Displacement: double (nullable = true)\n",
            " |-- Horsepower: double (nullable = true)\n",
            " |-- Weight: decimal(4,0) (nullable = true)\n",
            " |-- Acceleration: double (nullable = true)\n",
            " |-- Model: integer (nullable = true)\n",
            " |-- Origin: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOvqONYP0pp-"
      },
      "source": [
        "As you can see, the datatype has been infered automatically spark with even the correct precison for decimal type. A problem that might arise here is that sometimes, when you have to read multiple files with different schemas in different files, there might be an issue with implicit inferring leading to null values in some columns. Therefore, let us also see how to define schemas explicitly.\n",
        "\n",
        "#### Defining Schema Explicitly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxJ-RvZW0uYR",
        "outputId": "e3e51f9d-58da-4b2e-b771-cf05b8b59c0f"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "df.columns"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Car',\n",
              " 'MPG',\n",
              " 'Cylinders',\n",
              " 'Displacement',\n",
              " 'Horsepower',\n",
              " 'Weight',\n",
              " 'Acceleration',\n",
              " 'Model',\n",
              " 'Origin']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5OOXlrK09yU"
      },
      "source": [
        "# Creating a list of the schema in the format column_name, data_type\n",
        "labels = [\n",
        "     ('Car',StringType()),\n",
        "     ('MPG',DoubleType()),\n",
        "     ('Cylinders',IntegerType()),\n",
        "     ('Displacement',DoubleType()),\n",
        "     ('Horsepower',DoubleType()),\n",
        "     ('Weight',DoubleType()),\n",
        "     ('Acceleration',DoubleType()),\n",
        "     ('Model',IntegerType()),\n",
        "     ('Origin',StringType())\n",
        "]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmobAV5q1HaI",
        "outputId": "26c5616e-61cc-4709-bd08-48931aac485c"
      },
      "source": [
        "# Creating the schema that will be passed when reading the csv\n",
        "schema = StructType([StructField (x[0], x[1], True) for x in labels])\n",
        "schema"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType(List(StructField(Car,StringType,true),StructField(MPG,DoubleType,true),StructField(Cylinders,IntegerType,true),StructField(Displacement,DoubleType,true),StructField(Horsepower,DoubleType,true),StructField(Weight,DoubleType,true),StructField(Acceleration,DoubleType,true),StructField(Model,IntegerType,true),StructField(Origin,StringType,true)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3rnF6FyDt3P",
        "outputId": "b4e7bdec-44c6-436a-b765-88066cb8f92a"
      },
      "source": [
        "df = spark.read.csv('cars.csv', header=True, sep=\";\", schema=schema)\n",
        "df.printSchema()\n",
        "# The schema comes as we gave!"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Car: string (nullable = true)\n",
            " |-- MPG: double (nullable = true)\n",
            " |-- Cylinders: integer (nullable = true)\n",
            " |-- Displacement: double (nullable = true)\n",
            " |-- Horsepower: double (nullable = true)\n",
            " |-- Weight: double (nullable = true)\n",
            " |-- Acceleration: double (nullable = true)\n",
            " |-- Model: integer (nullable = true)\n",
            " |-- Origin: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRkPt35yDwj2",
        "outputId": "b7c9938a-c74f-457b-9340-0a3b4fb38c3a"
      },
      "source": [
        "df.show(truncate=False)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|Car                             |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|\n",
            "+--------------------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|Chevrolet Chevelle Malibu       |18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |\n",
            "|Buick Skylark 320               |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |\n",
            "|Plymouth Satellite              |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |\n",
            "|AMC Rebel SST                   |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |\n",
            "|Ford Torino                     |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |\n",
            "|Ford Galaxie 500                |15.0|8        |429.0       |198.0     |4341.0|10.0        |70   |US    |\n",
            "|Chevrolet Impala                |14.0|8        |454.0       |220.0     |4354.0|9.0         |70   |US    |\n",
            "|Plymouth Fury iii               |14.0|8        |440.0       |215.0     |4312.0|8.5         |70   |US    |\n",
            "|Pontiac Catalina                |14.0|8        |455.0       |225.0     |4425.0|10.0        |70   |US    |\n",
            "|AMC Ambassador DPL              |15.0|8        |390.0       |190.0     |3850.0|8.5         |70   |US    |\n",
            "|Citroen DS-21 Pallas            |0.0 |4        |133.0       |115.0     |3090.0|17.5        |70   |Europe|\n",
            "|Chevrolet Chevelle Concours (sw)|0.0 |8        |350.0       |165.0     |4142.0|11.5        |70   |US    |\n",
            "|Ford Torino (sw)                |0.0 |8        |351.0       |153.0     |4034.0|11.0        |70   |US    |\n",
            "|Plymouth Satellite (sw)         |0.0 |8        |383.0       |175.0     |4166.0|10.5        |70   |US    |\n",
            "|AMC Rebel SST (sw)              |0.0 |8        |360.0       |175.0     |3850.0|11.0        |70   |US    |\n",
            "|Dodge Challenger SE             |15.0|8        |383.0       |170.0     |3563.0|10.0        |70   |US    |\n",
            "|Plymouth 'Cuda 340              |14.0|8        |340.0       |160.0     |3609.0|8.0         |70   |US    |\n",
            "|Ford Mustang Boss 302           |0.0 |8        |302.0       |140.0     |3353.0|8.0         |70   |US    |\n",
            "|Chevrolet Monte Carlo           |15.0|8        |400.0       |150.0     |3761.0|9.5         |70   |US    |\n",
            "|Buick Estate Wagon (sw)         |14.0|8        |455.0       |225.0     |3086.0|10.0        |70   |US    |\n",
            "+--------------------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jinqcKL-EDJW"
      },
      "source": [
        "As we can see here, the data has been successully loaded with the specified datatypes.\n",
        "\n",
        "\n",
        "### DataFrame Operations on Columns¶\n",
        "We will go over the following in this section:\n",
        "\n",
        "- Selecting Columns\n",
        "- Selecting Multiple Columns\n",
        "- Adding New Columns\n",
        "- Renaming Columns\n",
        "- Grouping By Columns\n",
        "- Removing Columns\n",
        "\n",
        "#### Selecting Columns\n",
        "There are multiple ways to do a select in PySpark. You can find how they differ and how each below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30exvXOoEgKz",
        "outputId": "2b7fb7a0-e27f-4e4e-fa2f-711698a3c491"
      },
      "source": [
        "# 1st method\n",
        "# Column name is case sensitive in this usage\n",
        "print(df.Car)\n",
        "print(\"*\"*20)\n",
        "df.select(df.Car).show(truncate=False)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column<'Car'>\n",
            "********************\n",
            "+--------------------------------+\n",
            "|Car                             |\n",
            "+--------------------------------+\n",
            "|Chevrolet Chevelle Malibu       |\n",
            "|Buick Skylark 320               |\n",
            "|Plymouth Satellite              |\n",
            "|AMC Rebel SST                   |\n",
            "|Ford Torino                     |\n",
            "|Ford Galaxie 500                |\n",
            "|Chevrolet Impala                |\n",
            "|Plymouth Fury iii               |\n",
            "|Pontiac Catalina                |\n",
            "|AMC Ambassador DPL              |\n",
            "|Citroen DS-21 Pallas            |\n",
            "|Chevrolet Chevelle Concours (sw)|\n",
            "|Ford Torino (sw)                |\n",
            "|Plymouth Satellite (sw)         |\n",
            "|AMC Rebel SST (sw)              |\n",
            "|Dodge Challenger SE             |\n",
            "|Plymouth 'Cuda 340              |\n",
            "|Ford Mustang Boss 302           |\n",
            "|Chevrolet Monte Carlo           |\n",
            "|Buick Estate Wagon (sw)         |\n",
            "+--------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fsA6teXEwWT"
      },
      "source": [
        "Note: We can't always use the dot notation because this will break when the column names have reserved names or attributes to the data frame class. Additionally, the column names are case sensitive in nature so we need to always make sure the column names have been changed to a paticular case before using it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_z9Gf7GE3FR",
        "outputId": "969944f4-8795-4ba1-f3ca-4477ea5cdaf1"
      },
      "source": [
        "# 2nd method\n",
        "# Column name is case insensitive here\n",
        "print(df['car'])\n",
        "print(\"*\"*20)\n",
        "df.select(df['car']).show(truncate=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column<'car'>\n",
            "********************\n",
            "+--------------------------------+\n",
            "|car                             |\n",
            "+--------------------------------+\n",
            "|Chevrolet Chevelle Malibu       |\n",
            "|Buick Skylark 320               |\n",
            "|Plymouth Satellite              |\n",
            "|AMC Rebel SST                   |\n",
            "|Ford Torino                     |\n",
            "|Ford Galaxie 500                |\n",
            "|Chevrolet Impala                |\n",
            "|Plymouth Fury iii               |\n",
            "|Pontiac Catalina                |\n",
            "|AMC Ambassador DPL              |\n",
            "|Citroen DS-21 Pallas            |\n",
            "|Chevrolet Chevelle Concours (sw)|\n",
            "|Ford Torino (sw)                |\n",
            "|Plymouth Satellite (sw)         |\n",
            "|AMC Rebel SST (sw)              |\n",
            "|Dodge Challenger SE             |\n",
            "|Plymouth 'Cuda 340              |\n",
            "|Ford Mustang Boss 302           |\n",
            "|Chevrolet Monte Carlo           |\n",
            "|Buick Estate Wagon (sw)         |\n",
            "+--------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It6tEdy8FD4z",
        "outputId": "39c470a5-227c-46c9-cdec-9abf9cb01f0f"
      },
      "source": [
        "# 3rd method\n",
        "# Column name is case insensitive here\n",
        "from pyspark.sql.functions import col\n",
        "df.select(col('car')).show(truncate=False)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------+\n",
            "|car                             |\n",
            "+--------------------------------+\n",
            "|Chevrolet Chevelle Malibu       |\n",
            "|Buick Skylark 320               |\n",
            "|Plymouth Satellite              |\n",
            "|AMC Rebel SST                   |\n",
            "|Ford Torino                     |\n",
            "|Ford Galaxie 500                |\n",
            "|Chevrolet Impala                |\n",
            "|Plymouth Fury iii               |\n",
            "|Pontiac Catalina                |\n",
            "|AMC Ambassador DPL              |\n",
            "|Citroen DS-21 Pallas            |\n",
            "|Chevrolet Chevelle Concours (sw)|\n",
            "|Ford Torino (sw)                |\n",
            "|Plymouth Satellite (sw)         |\n",
            "|AMC Rebel SST (sw)              |\n",
            "|Dodge Challenger SE             |\n",
            "|Plymouth 'Cuda 340              |\n",
            "|Ford Mustang Boss 302           |\n",
            "|Chevrolet Monte Carlo           |\n",
            "|Buick Estate Wagon (sw)         |\n",
            "+--------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CnYGD8cFZae"
      },
      "source": [
        "### Selecting Multiple Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlTVpH2nFhD-",
        "outputId": "4cd81ca7-8f22-4547-fa68-ea3d45601e39"
      },
      "source": [
        "# 1st method\n",
        "# Column name is case sensitive in this usage\n",
        "print(df.Car, df.Cylinders)\n",
        "print(\"*\"*40)\n",
        "df.select(df.Car, df.Cylinders).show(truncate=False)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column<'Car'> Column<'Cylinders'>\n",
            "****************************************\n",
            "+--------------------------------+---------+\n",
            "|Car                             |Cylinders|\n",
            "+--------------------------------+---------+\n",
            "|Chevrolet Chevelle Malibu       |8        |\n",
            "|Buick Skylark 320               |8        |\n",
            "|Plymouth Satellite              |8        |\n",
            "|AMC Rebel SST                   |8        |\n",
            "|Ford Torino                     |8        |\n",
            "|Ford Galaxie 500                |8        |\n",
            "|Chevrolet Impala                |8        |\n",
            "|Plymouth Fury iii               |8        |\n",
            "|Pontiac Catalina                |8        |\n",
            "|AMC Ambassador DPL              |8        |\n",
            "|Citroen DS-21 Pallas            |4        |\n",
            "|Chevrolet Chevelle Concours (sw)|8        |\n",
            "|Ford Torino (sw)                |8        |\n",
            "|Plymouth Satellite (sw)         |8        |\n",
            "|AMC Rebel SST (sw)              |8        |\n",
            "|Dodge Challenger SE             |8        |\n",
            "|Plymouth 'Cuda 340              |8        |\n",
            "|Ford Mustang Boss 302           |8        |\n",
            "|Chevrolet Monte Carlo           |8        |\n",
            "|Buick Estate Wagon (sw)         |8        |\n",
            "+--------------------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvSYbMo0H5sa",
        "outputId": "44696cd1-47c4-4c1e-abf1-a7db8fe9c177"
      },
      "source": [
        "# 2nd method\n",
        "# Column name is case insensitive in this usage\n",
        "print(df['car'],df['cylinders'])\n",
        "print(\"*\"*40)\n",
        "df.select(df['car'],df['cylinders']).show(truncate=False)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column<'car'> Column<'cylinders'>\n",
            "****************************************\n",
            "+--------------------------------+---------+\n",
            "|car                             |cylinders|\n",
            "+--------------------------------+---------+\n",
            "|Chevrolet Chevelle Malibu       |8        |\n",
            "|Buick Skylark 320               |8        |\n",
            "|Plymouth Satellite              |8        |\n",
            "|AMC Rebel SST                   |8        |\n",
            "|Ford Torino                     |8        |\n",
            "|Ford Galaxie 500                |8        |\n",
            "|Chevrolet Impala                |8        |\n",
            "|Plymouth Fury iii               |8        |\n",
            "|Pontiac Catalina                |8        |\n",
            "|AMC Ambassador DPL              |8        |\n",
            "|Citroen DS-21 Pallas            |4        |\n",
            "|Chevrolet Chevelle Concours (sw)|8        |\n",
            "|Ford Torino (sw)                |8        |\n",
            "|Plymouth Satellite (sw)         |8        |\n",
            "|AMC Rebel SST (sw)              |8        |\n",
            "|Dodge Challenger SE             |8        |\n",
            "|Plymouth 'Cuda 340              |8        |\n",
            "|Ford Mustang Boss 302           |8        |\n",
            "|Chevrolet Monte Carlo           |8        |\n",
            "|Buick Estate Wagon (sw)         |8        |\n",
            "+--------------------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_ZtGc6IH_jn",
        "outputId": "8eccc56d-0ce7-49af-a79c-800d2bff90b9"
      },
      "source": [
        "# 3rd method\n",
        "# Column name is case insensitive in this usage\n",
        "from pyspark.sql.functions import col\n",
        "df.select(col('car'),col('cylinders')).show(truncate=False)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------+---------+\n",
            "|car                             |cylinders|\n",
            "+--------------------------------+---------+\n",
            "|Chevrolet Chevelle Malibu       |8        |\n",
            "|Buick Skylark 320               |8        |\n",
            "|Plymouth Satellite              |8        |\n",
            "|AMC Rebel SST                   |8        |\n",
            "|Ford Torino                     |8        |\n",
            "|Ford Galaxie 500                |8        |\n",
            "|Chevrolet Impala                |8        |\n",
            "|Plymouth Fury iii               |8        |\n",
            "|Pontiac Catalina                |8        |\n",
            "|AMC Ambassador DPL              |8        |\n",
            "|Citroen DS-21 Pallas            |4        |\n",
            "|Chevrolet Chevelle Concours (sw)|8        |\n",
            "|Ford Torino (sw)                |8        |\n",
            "|Plymouth Satellite (sw)         |8        |\n",
            "|AMC Rebel SST (sw)              |8        |\n",
            "|Dodge Challenger SE             |8        |\n",
            "|Plymouth 'Cuda 340              |8        |\n",
            "|Ford Mustang Boss 302           |8        |\n",
            "|Chevrolet Monte Carlo           |8        |\n",
            "|Buick Estate Wagon (sw)         |8        |\n",
            "+--------------------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxXe8fnvIMk4"
      },
      "source": [
        "#### Adding New Columns¶\n",
        "We will take a look at three cases here:\n",
        "\n",
        "- Adding a new column\n",
        "- Adding multiple columns\n",
        "- Deriving a new column from an exisitng one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc3FnYLfH6S0",
        "outputId": "69adda32-bc4d-4597-a0ba-866d6fcec89d"
      },
      "source": [
        "# CASE 1: Adding a new column\n",
        "# We will add a new column called 'first_column' at the end\n",
        "from pyspark.sql.functions import lit\n",
        "df = df.withColumn('first_column',lit(1))\n",
        "# lit means literal. It populates the row with the literal value given.\n",
        "# When adding static data / constant values, it is a good practice to use it.\n",
        "df.show(5,truncate=False)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|first_column|\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |1           |\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |1           |\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |1           |\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |1           |\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |1           |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cElzhC0WH6Z0",
        "outputId": "60a88cf8-7144-4d75-d16d-e6b4c38a7934"
      },
      "source": [
        "# CASE 2: Adding multiple columns\n",
        "# We will add two new columns called 'second_column' and 'third_column' at the end\n",
        "df = df.withColumn('second_column', lit(2)) \\\n",
        "       .withColumn('third_column', lit('Third Column'))\n",
        "# lit means literal. It populates the row with the literal value given.\n",
        "# When adding static data / constant values, it is a good practice to use it.\n",
        "df.show(5,truncate=False)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|first_column|second_column|third_column|\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |1           |2            |Third Column|\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |1           |2            |Third Column|\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |1           |2            |Third Column|\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |1           |2            |Third Column|\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |1           |2            |Third Column|\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh-3GeSvJPgU",
        "outputId": "4a1b2b8b-a0bb-43c3-d74b-438fc7eaa4f3"
      },
      "source": [
        "# CASE 3: Deriving a new column from an exisitng one\n",
        "# We will add a new column called 'car_model' which has the value of car and model appended together with a space in between \n",
        "from pyspark.sql.functions import concat\n",
        "df = df.withColumn('car_model', concat(col(\"Car\"), lit(\" \"), col(\"model\")))\n",
        "# lit means literal. It populates the row with the literal value given.\n",
        "# When adding static data / constant values, it is a good practice to use it.\n",
        "df.show(5,truncate=False)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+----------------------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|first_column|second_column|third_column|car_model                   |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+----------------------------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |1           |2            |Third Column|Chevrolet Chevelle Malibu 70|\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |1           |2            |Third Column|Buick Skylark 320 70        |\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |1           |2            |Third Column|Plymouth Satellite 70       |\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |1           |2            |Third Column|AMC Rebel SST 70            |\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |1           |2            |Third Column|Ford Torino 70              |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+------------+-------------+------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiaZAbTnLf2-"
      },
      "source": [
        "As we can see, the new column car model has been created from existing columns. Since our aim was to create a column which has the value of car and model appended together with a space in between we have used the concat operator.\n",
        "\n",
        "#### Renaming Columns\n",
        "We use the withColumnRenamed function to rename a columm in PySpark. Let us see it in action below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouEBxJX5LWlb",
        "outputId": "1d54cfb2-59bc-4fdf-f193-900ac1aa303c"
      },
      "source": [
        "#Renaming a column in PySpark\n",
        "df = df.withColumnRenamed('first_column', 'new_column_one') \\\n",
        "       .withColumnRenamed('second_column', 'new_column_two') \\\n",
        "       .withColumnRenamed('third_column', 'new_column_three')\n",
        "df.show(truncate=False)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+--------------+----------------+-----------------------------------+\n",
            "|Car                             |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|new_column_one|new_column_two|new_column_three|car_model                          |\n",
            "+--------------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+--------------+----------------+-----------------------------------+\n",
            "|Chevrolet Chevelle Malibu       |18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |1             |2             |Third Column    |Chevrolet Chevelle Malibu 70       |\n",
            "|Buick Skylark 320               |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |1             |2             |Third Column    |Buick Skylark 320 70               |\n",
            "|Plymouth Satellite              |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |1             |2             |Third Column    |Plymouth Satellite 70              |\n",
            "|AMC Rebel SST                   |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |1             |2             |Third Column    |AMC Rebel SST 70                   |\n",
            "|Ford Torino                     |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |1             |2             |Third Column    |Ford Torino 70                     |\n",
            "|Ford Galaxie 500                |15.0|8        |429.0       |198.0     |4341.0|10.0        |70   |US    |1             |2             |Third Column    |Ford Galaxie 500 70                |\n",
            "|Chevrolet Impala                |14.0|8        |454.0       |220.0     |4354.0|9.0         |70   |US    |1             |2             |Third Column    |Chevrolet Impala 70                |\n",
            "|Plymouth Fury iii               |14.0|8        |440.0       |215.0     |4312.0|8.5         |70   |US    |1             |2             |Third Column    |Plymouth Fury iii 70               |\n",
            "|Pontiac Catalina                |14.0|8        |455.0       |225.0     |4425.0|10.0        |70   |US    |1             |2             |Third Column    |Pontiac Catalina 70                |\n",
            "|AMC Ambassador DPL              |15.0|8        |390.0       |190.0     |3850.0|8.5         |70   |US    |1             |2             |Third Column    |AMC Ambassador DPL 70              |\n",
            "|Citroen DS-21 Pallas            |0.0 |4        |133.0       |115.0     |3090.0|17.5        |70   |Europe|1             |2             |Third Column    |Citroen DS-21 Pallas 70            |\n",
            "|Chevrolet Chevelle Concours (sw)|0.0 |8        |350.0       |165.0     |4142.0|11.5        |70   |US    |1             |2             |Third Column    |Chevrolet Chevelle Concours (sw) 70|\n",
            "|Ford Torino (sw)                |0.0 |8        |351.0       |153.0     |4034.0|11.0        |70   |US    |1             |2             |Third Column    |Ford Torino (sw) 70                |\n",
            "|Plymouth Satellite (sw)         |0.0 |8        |383.0       |175.0     |4166.0|10.5        |70   |US    |1             |2             |Third Column    |Plymouth Satellite (sw) 70         |\n",
            "|AMC Rebel SST (sw)              |0.0 |8        |360.0       |175.0     |3850.0|11.0        |70   |US    |1             |2             |Third Column    |AMC Rebel SST (sw) 70              |\n",
            "|Dodge Challenger SE             |15.0|8        |383.0       |170.0     |3563.0|10.0        |70   |US    |1             |2             |Third Column    |Dodge Challenger SE 70             |\n",
            "|Plymouth 'Cuda 340              |14.0|8        |340.0       |160.0     |3609.0|8.0         |70   |US    |1             |2             |Third Column    |Plymouth 'Cuda 340 70              |\n",
            "|Ford Mustang Boss 302           |0.0 |8        |302.0       |140.0     |3353.0|8.0         |70   |US    |1             |2             |Third Column    |Ford Mustang Boss 302 70           |\n",
            "|Chevrolet Monte Carlo           |15.0|8        |400.0       |150.0     |3761.0|9.5         |70   |US    |1             |2             |Third Column    |Chevrolet Monte Carlo 70           |\n",
            "|Buick Estate Wagon (sw)         |14.0|8        |455.0       |225.0     |3086.0|10.0        |70   |US    |1             |2             |Third Column    |Buick Estate Wagon (sw) 70         |\n",
            "+--------------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+--------------+----------------+-----------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuUyZZMoM5qN"
      },
      "source": [
        "#### Grouping By Columns¶\n",
        "Here, we see the Dataframe API way of grouping values. We will discuss how to:\n",
        "\n",
        "- Group By a single column\n",
        "- Group By multiple columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hIh8SWMXmLX",
        "outputId": "bd1e870f-234b-4621-b14e-70fc1784be4f"
      },
      "source": [
        "# Group By a column in PySpark\n",
        "df.groupBy('Origin').count().show(5)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|Origin|count|\n",
            "+------+-----+\n",
            "|Europe|   73|\n",
            "|    US|  254|\n",
            "| Japan|   79|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMmMrpG6aK1t",
        "outputId": "987b8711-37a6-4613-fd5e-8338c06945fe"
      },
      "source": [
        "# Group By multiple columns in PySpark\n",
        "df.groupBy('Origin', 'Model').count().show(5)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+-----+\n",
            "|Origin|Model|count|\n",
            "+------+-----+-----+\n",
            "|Europe|   71|    5|\n",
            "|Europe|   80|    9|\n",
            "|Europe|   79|    4|\n",
            "| Japan|   75|    4|\n",
            "|    US|   72|   18|\n",
            "+------+-----+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMMRDmdNbToI"
      },
      "source": [
        "#### Removing Columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35_3igz_bXj3",
        "outputId": "0bcbbc66-b610-4a91-f868-ca32170ca18e"
      },
      "source": [
        "#Remove columns in PySpark\n",
        "df = df.drop('new_column_one')\n",
        "df.show(5,truncate=False)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+----------------+----------------------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|new_column_two|new_column_three|car_model                   |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+----------------+----------------------------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |2             |Third Column    |Chevrolet Chevelle Malibu 70|\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |2             |Third Column    |Buick Skylark 320 70        |\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |2             |Third Column    |Plymouth Satellite 70       |\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |2             |Third Column    |AMC Rebel SST 70            |\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |2             |Third Column    |Ford Torino 70              |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+--------------+----------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu6-Q0bUbpBS",
        "outputId": "5583b161-0de0-4fa0-bd16-fe2b9284a330"
      },
      "source": [
        "#Remove multiple columnss in one go\n",
        "df = df.drop('new_column_two') \\\n",
        "       .drop('new_column_three')\n",
        "df.show(5,truncate=False)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+----------------------------+\n",
            "|Car                      |MPG |Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|car_model                   |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+----------------------------+\n",
            "|Chevrolet Chevelle Malibu|18.0|8        |307.0       |130.0     |3504.0|12.0        |70   |US    |Chevrolet Chevelle Malibu 70|\n",
            "|Buick Skylark 320        |15.0|8        |350.0       |165.0     |3693.0|11.5        |70   |US    |Buick Skylark 320 70        |\n",
            "|Plymouth Satellite       |18.0|8        |318.0       |150.0     |3436.0|11.0        |70   |US    |Plymouth Satellite 70       |\n",
            "|AMC Rebel SST            |16.0|8        |304.0       |150.0     |3433.0|12.0        |70   |US    |AMC Rebel SST 70            |\n",
            "|Ford Torino              |17.0|8        |302.0       |140.0     |3449.0|10.5        |70   |US    |Ford Torino 70              |\n",
            "+-------------------------+----+---------+------------+----------+------+------------+-----+------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}